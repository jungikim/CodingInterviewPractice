{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da76e920-8b71-4830-9c4a-ca51879f9a2e",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "y = sigmoid(XW + b)\n",
    "z = XW + b\n",
    "\n",
    "X: B x d\n",
    "W: d\n",
    "b: d\n",
    "\n",
    "\n",
    "sigmoid: 1 / (1+ e^-x)\n",
    "\n",
    "cross entropy loss\n",
    "\n",
    "CEloss = - 1/M sigma over m in M \\[ ylog(y') + (1-y)log(1-y') \\]\n",
    "\n",
    "M: number of instances\n",
    "y: true label\n",
    "y': predicted label\n",
    "\n",
    "\n",
    "stochastic gradient descent\n",
    "\n",
    "```\n",
    "w' <- w - d loss / d w\n",
    "b' <- b - d loss / d b\n",
    "\n",
    "derivative of log(x) = 1/x\n",
    "derivative of sigmoid(x) = x * (1-x)\n",
    "\n",
    "sigmoid(x) = 1 / (1+e^-x) = (1+e^-x)^-1\n",
    "derivative of sigmoid(x) = -1 * (1+e^-x)^-2 * -e^-x\n",
    "                         = e^-x / (1+e^-x)^2\n",
    "                         = (1+e^-x) / (1+e^-x)^2 - 1 / (1+e^-x)^2\n",
    "                    factor out 1/1+e^-x\n",
    "                         = 1/(1+e^-x) * ( 1 - 1/(1+e^-x))\n",
    "                    1/(1+e^-x) is sigmoid\n",
    "                         = sigmoid(x) * (1 - sigmoid(x))\n",
    "```\n",
    "let a = sigmoid(x)\n",
    "\n",
    "by chain rule,\n",
    "```\n",
    "d loss / d w =  d loss / d a * d a / d z * d z / d w\n",
    "d loss / d b =  d loss / d a * d a / d z * d z / d b\n",
    "```\n",
    "```\n",
    "d loss / d a =   - y/a  + (1-y)/(1-a)\n",
    "             =  (-y * (1-a) + (1-y) *a ) / (a * (1-a))\n",
    "             =  ( -y + ay + a - ay ) / (a * (1-a))\n",
    "             =  (a - y ) / (a * (1-a))\n",
    "d a / d z =   a * ( 1 - a )\n",
    "\n",
    "d loss / d w =  ( a - y ) / (a * (1-a))  * a * ( 1 - a) * x\n",
    "             =  ( a - y ) * x\n",
    "\n",
    "d loss / d b =  ( a - y )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ad192a3-38f7-457d-ac9f-5badcbd16dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3819, 0.5943],\n",
      "        [0.7960, 0.6891],\n",
      "        [0.4285, 0.6055],\n",
      "        [0.9607, 0.7233],\n",
      "        [0.6932, 0.6667]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "B=5\n",
    "D=3\n",
    "\n",
    "input=torch.randn(B,D)\n",
    "y=torch.rand(B)\n",
    "print(torch.cat([y[:,np.newaxis], torch.sigmoid(y)[:,np.newaxis]],dim=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f710fa24-b607-4e02-9296-5bec42851126",
   "metadata": {},
   "source": [
    "Derivatives of softmax,  mean squared error\n",
    "\n",
    "\n",
    "```\n",
    "s_i =  e^Z_i / sigma l..n [  e^z_l ]\n",
    "\n",
    "\n",
    "d log( s_i ) / d z  =  1 / s_i  * d s_i / d z\n",
    "\n",
    "d s_i / d z =  s_i *  d log (s_i ) / d z\n",
    "\n",
    "log (s_i ) =  z_i  - log ( sigma l..n e^z_l )\n",
    "\n",
    "d log (s_i ) / d z =    d z_i / d z_j   - d log (sigma l..n e^z_l ) / d z_j\n",
    "\n",
    "\n",
    "d z_i / d z_j  = 1 if i == j else 0\n",
    "\n",
    "\n",
    "d logx / dx  =  1/ x\n",
    "\n",
    "d log (sigma l..n e^z_l ) / d z_j =  d log [ e^z_1 + ... e^z_n ] / d z_j  = d log( e^z_j ) / d d_j = z_j\n",
    "\n",
    "\n",
    "d s_i / d z_j  = s_i * ( 1 if i==j else 0    -  s_j  )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223ff3b-2ecb-4588-ae07-97e4a0d95523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
